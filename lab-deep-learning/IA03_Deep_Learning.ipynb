{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "IA03 - Deep Learning.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LNp6DM3Jj9kT"
      },
      "source": [
        "# Taller de Deep Learning con Pytorch\n",
        "## Entrenando una CNN como clasificador\n",
        "\n",
        "__Creado por:__ Angel Ayala ([Github](https://github.com/angel-ayala))\n",
        "\n",
        "__Revisado:__ Francisco Cruz ([Sitio Web](http://www.franciscocruz.cl))\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-asc09gikJG9"
      },
      "source": [
        "__Completado por:__ _indique su nombre aqui_\n",
        "\n",
        "__Actualizado__: Martes 10 de Mayo, 2022\n",
        "\n",
        "__Fecha de Entrega__: Viernes 20 de Mayo, 2022\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IU4ScvMPmiRl"
      },
      "source": [
        "# Actividad\n",
        "En el siguiente tutorial veremos la aplicación de una red neuronal convolucional (CNN, del inglés _Convolutional Neural Network_) para un problema de clasificación de imágenes. Para este propósito, utilizaremos la librería PyTorch en gran parte del proceso, facilitando la carga y preprocesamiento del conjunto de datos, así como también crear, entrenar y validar nuestro modelo de la misma forma que en el taller anterior. En este taller además abordaremos el uso de _transfer learning_ y de _fine-tuning_ para acelerar el proceso de entrenamiento.\n",
        "\n",
        "En este taller implementaremos las misma base para la creación de un modelo que corresponde a:\n",
        "- Obtención del conjunto de datos.\n",
        "- Análisis del conjunto de datos.\n",
        "- Preprocesamiento de los datos.\n",
        "- Definición del modelo.\n",
        "- Entrenamiento y validación del modelo.\n",
        "- Pruebas de generalización.\n",
        "\n",
        "## Objetivos\n",
        "Como objetivo de este taller se encuentra que sean capaces de crear una arquitectura de red neuronal convolucional usando las herramientas actuales para la implementación de deep learning. Para esto se espera que consigan:\n",
        "- Aprender a utilizar la librería de PyTorch para ejecutar un experimento de deep learning.\n",
        "- Desarrollar una CNN a partir del contenido visto en clases.\n",
        "- Identificar las diferencias entre un modelo perceptrón multicapa y un modelo convolucional.\n",
        "- Implementar el uso de _transfer learning_/_fine-tuning_ con arquitecturas clásicas de deep learning.\n",
        "- Usar métricas de evaluación para un modelo de clasificación\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TrAnMhcQyzcS"
      },
      "source": [
        "# Desarrollo\n",
        "\n",
        "Para el desarrollo de esta actividad, debemos recordar que usaremos el lenguaje de programación de Python y sus librerías asociadas para el tratamiento de variables. Dentro del notebook se encuentra todo lo necesario para realizar un experimento de clasificación de imágenes con PyTorch, a medida se avanza en el notebook se encontrarán con celdas de código completos que explican el uso o implementación de ciertas librerías que serán de utilidad para una experiencia futura, otras celdas con código parciales para ustedes complementar con la lógica faltante, y otras celdas que deberán programar por completo. Para finalizar, al final del notebook se encuentran unos enunciados de análisis de la experiencia desarrollada en este notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9ISMb8SSjGQX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form",
        "outputId": "2d62874f-38e2-48bf-9b34-0b1e88f6fa1d"
      },
      "source": [
        "#@title Cargar Librerías\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from sklearn.metrics import roc_curve, auc\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.metrics import multilabel_confusion_matrix\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Get cpu or gpu device for training.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using cuda device\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_B1AUr0eZA1j",
        "cellView": "form"
      },
      "source": [
        "#@title Métodos útiles\n",
        "# Definir forma de entrenamiento\n",
        "def entrenar(dataloader, model, loss_fn, optimizer, quiet=True):\n",
        "    model.train()  # cambia el estado para entrenamiento\n",
        "    # iterar sobre el conjunto de lotes\n",
        "    size = len(dataloader.dataset)\n",
        "    error = []\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        # pasa los tensores a GPU o CPU\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        \n",
        "        # Feed-forward y cálculo del error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "        error.append(loss.item())\n",
        "        \n",
        "        # Backpropagation\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Imprimir estado de entrenamiento\n",
        "        if batch % 100 == 99 and quiet is False:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "# Definir forma de evaluación\n",
        "def evaluar(dataloader, model):\n",
        "    model.eval()  # Cambia el estado para evaluación\n",
        "    test_loss, correct = 0, 0\n",
        "    size = len(dataloader.dataset)\n",
        "    predictions = []\n",
        "    # Evita el calculo de gradientes\n",
        "    with torch.no_grad():\n",
        "    # Iterar sobre el conjunto de lotes\n",
        "        for X, y in dataloader:\n",
        "            # Pasa los tensores a GPU o CPU\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            # Feed-forward y cálculo del error\n",
        "            pred = model(X)\n",
        "            # Almacena métricas\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "            # Almacena predicciones\n",
        "            predictions.extend(pred.tolist())\n",
        "\n",
        "    test_loss /= size\n",
        "    correct /= size\n",
        "    # Imprimir métricas\n",
        "    print(f\"Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")\n",
        "    return predictions\n",
        "\n",
        "# Visualizar muestras\n",
        "def show_samples(data, labels, names, size=(5, 2), unormalize=None):\n",
        "    figure = plt.figure(figsize=size)\n",
        "    cols, rows = size\n",
        "\n",
        "    for i in range(1, cols * rows + 1):\n",
        "        img, label = data[i], labels[i]\n",
        "\n",
        "        if unormalize:\n",
        "            img = unormalize(img)        \n",
        "\n",
        "        figure.add_subplot(rows, cols, i)\n",
        "        plt.title(names[label])\n",
        "        plt.axis(\"off\")\n",
        "        plt.imshow(img)\n",
        "\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Du9iQckW0YJn"
      },
      "source": [
        "## Primera experiencia: MLP a CNN\n",
        "\n",
        "Para esta primera experiencia usaremos el conjunto de datos de [MNIST](https://deepai.org/dataset/mnist) que contiene 70.000 imágenes en blanco y negro de 28x28 pixeles en blanco y negro que representan los dígitos del cero al nueve. Los datos se dividen en dos subconjuntos, con 60.000 imágenes pertenecientes al conjunto de entrenamiento y 10.000 imágenes pertenecientes al conjunto de prueba. La separación de las imágenes garantiza que, dado lo que un modelo adecuadamente entrenado ha aprendido previamente, pueda clasificar con precisión imágenes relevantes no examinadas previamente."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOWlUSmX4zu1"
      },
      "source": [
        "### Cargar conjunto de datos"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGfzsyw2m9Kz"
      },
      "source": [
        "# Preprocesamiento\n",
        "preprocess = transforms.Compose(\n",
        "    [transforms.ToTensor(),                                 \n",
        "     transforms.Normalize(mean=(0.5), std=(0.5))])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Descargar datos de entrenamiento.\n",
        "training_data = datasets.MNIST(root=\"./data\", train=True,\n",
        "                               download=True, transform=preprocess)\n",
        "\n",
        "# Descargar datos de prueba.\n",
        "test_data = datasets.MNIST(root=\"./data\", train=False,\n",
        "                           download=True, transform=preprocess)\n",
        "\n",
        "# Separar conjunto en lotes\n",
        "mnist_loader = dict()\n",
        "mnist_loader['train'] = DataLoader(training_data, batch_size=batch_size,\n",
        "                                   shuffle=True, num_workers=2)\n",
        "mnist_loader['test'] = DataLoader(test_data, batch_size=batch_size,\n",
        "                                  shuffle=False, num_workers=2)\n",
        "\n",
        "classes = list(f\"Num{dig}\" for dig in range(10)) # números del 0 al 9"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "id": "9_cVT0zc5GyE",
        "cellView": "form",
        "outputId": "3ccf8e65-8e75-492b-86ad-85c989611b24"
      },
      "source": [
        "#@title Visualizar muestras\n",
        "# desnormalizar\n",
        "def unormalize(img):\n",
        "    inp = img.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.5, 0.5, 0.5])\n",
        "    std = np.array([0.5, 0.5, 0.5])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    return inp\n",
        "\n",
        "# obtener un lote\n",
        "muestras, labels = next(iter(mnist_loader['train']))\n",
        "show_samples(muestras, labels, classes, unormalize=unormalize)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 360x144 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXFdZorE8RLN"
      },
      "source": [
        "### Clasificación con un modelo totalmente contectado\n",
        "En este caso se desarrollará una arquitectura similar al perceptrón multicapa con en donde cada pixel de la imagen corresponde a una unidad, con una capa intermedia de 500 unidades y una salida con 10 unidades, obteniendo una arquitectura de (28*28)x500x10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wW3sJLknl4S"
      },
      "source": [
        "# Definir modelo MLP\n",
        "class MnistMlp(nn.Module):\n",
        "    def __init__(self, n_intermedia=512, output=10):\n",
        "        super(MnistMlp, self).__init__()\n",
        "        self.flatten = nn.Flatten()\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28 * 28, n_intermedia),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_intermedia, n_intermedia),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(n_intermedia, output),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x)\n",
        "        logits = self.linear_relu_stack(x)\n",
        "        return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nE-1vpktoDjC"
      },
      "source": [
        "#@title Instanciar y evaluar el modelo\n",
        "epochs = 5\n",
        "alfa = 1e-3\n",
        "\n",
        "mlp = MnistMlp().to(device)\n",
        "mlp_savename = \"model_mlp.pth\"\n",
        "print(mlp)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(mlp.parameters(), lr=alfa)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    entrenar(mnist_loader['train'], mlp, loss_fn, optimizer,\n",
        "             quiet=True)\n",
        "    evaluar(mnist_loader['test'], mlp)\n",
        "\n",
        "# Salvar los pesos modelo\n",
        "torch.save(mlp.state_dict(), mlp_savename)\n",
        "print(f\"Done!, Saved PyTorch Model State to {mlp_savename}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lz1Q2G-JoHq-"
      },
      "source": [
        "#@title Evaluar modelo\n",
        "# Instanciar modelo y cargar pesos\n",
        "mlp_eval = MnistMlp()\n",
        "mlp_eval.load_state_dict(torch.load(mlp_savename))\n",
        "mlp_eval.to(device)\n",
        "\n",
        "y_true = []\n",
        "\n",
        "for i, (x_input, y_label) in enumerate(mnist_loader['test']):\n",
        "    y_true.extend(y_label.tolist())\n",
        "\n",
        "y_pred = evaluar(mnist_loader['test'], mlp_eval)\n",
        "# softmax probabilities\n",
        "y_pred = F.softmax(torch.tensor(y_pred), dim=1).numpy()\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "print(classification_report(y_true, y_pred.argmax(axis=1),\n",
        "                            target_names=classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e1b3Hb55EKZQ"
      },
      "source": [
        "#@title ROC curve\n",
        "# roc\n",
        "idx_label = 9\n",
        "roc_y_true = np.array(y_true == idx_label, dtype=float)\n",
        "roc_y_pred = y_pred[:, idx_label]\n",
        "\n",
        "# Compute ROC curve and ROC area:\n",
        "fpr, tpr, _ = roc_curve(roc_y_true, roc_y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([-0.005, 1.0])\n",
        "plt.ylim([0.0, 1.007])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title(f'Receiver operating characteristic {classes[idx_label]}')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jWdc10Wt9pTS"
      },
      "source": [
        "### Definir el modelo CNN\n",
        "Crear una arquitectura de CNN en PyTorch es bastante simple, sigue la misma lógica que la creación de un MLP con la única diferencia que en vez de utilizar capas lineales o totalmente conectadas, se utilizan capas convolucionales, por ejemplo:\n",
        "- [nn.Conv2d](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html#torch.nn.Conv2d)\n",
        "- [nn.MaxPool](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html#torch.nn.MaxPool2d)\n",
        "- [nn.AvgPool](https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html#torch.nn.AvgPool2d)\n",
        "- [nn.Linear](https://pytorch.org/docs/stable/generated/torch.nn.Linear.html#torch.nn.Linear)\n",
        "\n",
        "Otra capa que será útil para la comunicación entre capas convolucionales y totalmente conectadas es [nn.Flatten](https://pytorch.org/docs/stable/generated/torch.nn.Flatten.html#torch.nn.Flatten)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3l7STB5P9uCK"
      },
      "source": [
        "# Define model\n",
        "class MnistCNN(nn.Module):\n",
        "    def __init__(self, input_channels=1, out_units=10, input_size=(28, 28)):\n",
        "        super(MnistCNN, self).__init__()\n",
        "        raise NotImplementedError('La función aún no se ha definido.')\n",
        "        # aqui se debe definir la arquitectura del modelo y sus respectivas\n",
        "        # capas\n",
        "\n",
        "    def forward(self, x):\n",
        "        raise NotImplementedError('La función aún no se ha definido.')\n",
        "        # aqui se debe definir como fluye la información desde la entrada\n",
        "        # a la salida\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IapCcU594Gt"
      },
      "source": [
        "#@title Instanciar y evaluar el modelo\n",
        "epochs = 5\n",
        "alfa = 1e-3\n",
        "\n",
        "cnn = MnistCNN().to(device)\n",
        "cnn_savename = \"model_cnn.pth\"\n",
        "print(cnn)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(cnn.parameters(), lr=alfa)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    entrenar(mnist_loader['train'], cnn, loss_fn, optimizer,\n",
        "             quiet=True)\n",
        "    evaluar(mnist_loader['test'], cnn)\n",
        "\n",
        "# Salvar los pesos modelo\n",
        "torch.save(cnn.state_dict(), cnn_savename)\n",
        "print(f\"Done!, Saved PyTorch Model State to {cnn_savename}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "28eCHK_J992F"
      },
      "source": [
        "#@title Evaluar modelo\n",
        "# Instanciar modelo y cargar pesos\n",
        "cnn_eval = MnistCNN()\n",
        "cnn_eval.load_state_dict(torch.load(cnn_savename))\n",
        "cnn_eval.to(device)\n",
        "\n",
        "y_true = []\n",
        "\n",
        "for i, (x_input, y_label) in enumerate(mnist_loader['test']):\n",
        "    y_true.extend(y_label.tolist())\n",
        "\n",
        "y_pred = evaluar(mnist_loader['test'], cnn_eval)\n",
        "# softmax probabilities\n",
        "y_pred = F.softmax(torch.tensor(y_pred), dim=1).numpy()\n",
        "y_true = np.array(y_true)\n",
        "\n",
        "print(classification_report(y_true, y_pred.argmax(axis=1),\n",
        "                            target_names=classes))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Zk-ZVLSygFF"
      },
      "source": [
        "#@title ROC curve\n",
        "# roc\n",
        "idx_label = 9\n",
        "roc_y_true = np.array(y_true == idx_label, dtype=float)\n",
        "roc_y_pred = y_pred[:, idx_label]\n",
        "\n",
        "# Compute ROC curve and ROC area:\n",
        "fpr, tpr, _ = roc_curve(roc_y_true, roc_y_pred)\n",
        "roc_auc = auc(fpr, tpr)\n",
        "\n",
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.4f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([-0.005, 1.0])\n",
        "plt.ylim([0.0, 1.007])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title(f'Receiver operating characteristic {classes[idx_label]}')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1qxAmKvFExHw"
      },
      "source": [
        "## Segunda experiencia: Usando modelos pre entrenados\n",
        "Los problemas de clasificación de imágenes ya han sido ampliamente abordados y hoy en día existen varios modelos con diferentes arquitecturas que han sido capaces de superar el ojo humano. Estos modelos han sido evaluados en el dataset de [ImageNet](https://image-net.org) que presenta más de 1.3 millones de imágenes entre 1000 clases diferentes de objetos.\n",
        "\n",
        "Para esta experiencia, usaremos el modelo propuesto por [Karen Simonyan llamado VGG16](https://arxiv.org/abs/1409.1556) que presenta la siguiente arquitectura:\n",
        "\n",
        "<img src=\"https://external-content.duckduckgo.com/iu/?u=https%3A%2F%2Fneurohive.io%2Fwp-content%2Fuploads%2F2018%2F11%2Fvgg16-1-e1542731207177.png&f=1&nofb=1\" width=\"600\"/>\n",
        "\n",
        "Comúnmente para utilizar _transfer learning_ desde modelos pre entrenados, se reemplaza la etapa de clasificación o de capas totalmente conectadas por una a elección, y sólo son actualizados esos parámetros de la red.\n",
        "\n",
        "Si las carácterísticas obtenidas por el modelo pre entrenado no  son suficientes, los parámetros de las capas convolucionales pueden ser actualizados pero usualmente su tasa de aprendizaje es mucho menor que el utilizado para las capas reemplazadas anteriormente, a esto se le conoce como _fine-tuning_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QRbFa5N4E50M"
      },
      "source": [
        "import torchvision.models as pretained_models"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uZJvDPLoYtlW"
      },
      "source": [
        "### Cargar conjunto de datos\n",
        "Para esta experiencia utilizaremos un conjunto más amplio en cantidad de clases a clasificar, demostrando la complejidad que puede existir en una tarea de clasificación.\n",
        "\n",
        "Para esta parte utilizaremos el conjunto CIFAR100 que consiste de 60.000 imágenes de 32x32 imágenes a color con 100 clases agrupadas en 20 superclases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kpuDr36xYs3A"
      },
      "source": [
        "# Preprocesamiento\n",
        "preprocess = transforms.Compose(\n",
        "    [transforms.Resize(224),\n",
        "     transforms.ToTensor(),\n",
        "     transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                          std=[0.229, 0.224, 0.225])])\n",
        "\n",
        "batch_size = 32\n",
        "\n",
        "# Descargar datos de entrenamiento.\n",
        "cifar_training = datasets.CIFAR100(root=\"./data\", train=True,\n",
        "                                   download=True, transform=preprocess)\n",
        "\n",
        "# Descargar datos de prueba.\n",
        "cifar_test = datasets.CIFAR100(root=\"./data\", train=False,\n",
        "                               download=True, transform=preprocess)\n",
        "\n",
        "# Separar conjunto en lotes\n",
        "cifar_loader = dict()\n",
        "cifar_loader['train'] = DataLoader(cifar_training, batch_size=batch_size,\n",
        "                                   shuffle=True, num_workers=2)\n",
        "cifar_loader['test'] = DataLoader(cifar_test, batch_size=batch_size,\n",
        "                                  shuffle=False, num_workers=2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "cellView": "form",
        "id": "6kvGaAfH_KMX"
      },
      "source": [
        "#@title leer etiquetas\n",
        "import pickle\n",
        "with open('/content/data/cifar-100-python/meta', 'rb') as fo:\n",
        "    cifar_meta = pickle.load(fo)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsvSybmJY1El",
        "cellView": "form"
      },
      "source": [
        "#@title Visualizar muestras\n",
        "# desnormalizar\n",
        "def unormalize(img):\n",
        "    inp = img.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    return inp\n",
        "\n",
        "# obtener un lote\n",
        "cifar_smpl, cifar_lbl = next(iter(cifar_loader['train']))\n",
        "show_samples(cifar_smpl, cifar_lbl, cifar_meta['fine_label_names'], unormalize=unormalize)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkbmJRUDdOGk"
      },
      "source": [
        "### Comparación con CNN simple"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v63pU82LdNbS"
      },
      "source": [
        "#@title Instanciar y evaluar el modelo\n",
        "epochs = 5\n",
        "\n",
        "cnn_cifar = MnistCNN(input_channels=3,\n",
        "                 out_units=100,\n",
        "                 input_size=(224, 224)).to(device)\n",
        "cnn_cifar_savename = \"model_cnn_cifar.pth\"\n",
        "print(cnn_cifar)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(cnn_cifar.parameters(), lr=1e-3)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    entrenar(cifar_loader['train'], cnn_cifar, loss_fn, optimizer,\n",
        "             quiet=False)\n",
        "    evaluar(cifar_loader['test'], cnn_cifar)\n",
        "\n",
        "# Salvar los pesos modelo\n",
        "torch.save(cnn_cifar.state_dict(), cnn_cifar_savename)\n",
        "print(f\"Done!, Saved PyTorch Model State to {cnn_savename}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl4aeKr9ZbeA"
      },
      "source": [
        "### Definición del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud6qTXOxZeFs"
      },
      "source": [
        "def VggBasedModel(n_outputs=10, fixed=True):\n",
        "    # extractor de características\n",
        "    # para mas información del modelo visite\n",
        "    # https://pytorch.org/vision/stable/_modules/torchvision/models/vgg.html\n",
        "    base_model = pretained_models.vgg16(pretrained=True)\n",
        "\n",
        "    if fixed:  # congelar los pesos del modelo\n",
        "        for param in base_model.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    # agregar capa totalmente conectada\n",
        "    num_ftrs = base_model.classifier[0].in_features  # número de características\n",
        "    base_model.classifier = nn.Linear(num_ftrs, n_outputs)\n",
        "\n",
        "    return base_model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H5nm8u-1ckqe"
      },
      "source": [
        "#@title Instanciar y entrenar el modelo\n",
        "epochs = 5\n",
        "\n",
        "vgg_based = VggBasedModel(n_outputs=100).to(device)\n",
        "vgg_based_savename = \"model_vgg_based.pth\"\n",
        "print(vgg_based)\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.SGD(vgg_based.parameters(), lr=1e-3)\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    entrenar(cifar_loader['train'], vgg_based, loss_fn, optimizer,\n",
        "             quiet=False)\n",
        "    evaluar(cifar_loader['test'], vgg_based)\n",
        "\n",
        "# Salvar los pesos modelo\n",
        "torch.save(vgg_based.state_dict(), vgg_based_savename)\n",
        "print(f\"Done!, Saved PyTorch Model State to {vgg_based_savename}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWh6Mb3C85Of"
      },
      "source": [
        "# Responda"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q_mI0xOdCP5J"
      },
      "source": [
        "## Para la primera experiencia:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30_4dxj7d_nP"
      },
      "source": [
        "(a) Defina una arquitectura propia de CNN e fundamente la selección de capas, conexiones y estructura definida."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "shoNyD9lCMIl"
      },
      "source": [
        "(b) Usando métricas compare su modelo de CNN con MLP. Comente las diferencias encontradas y el motivo de estas."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_7Obij--COtx"
      },
      "source": [
        "\n",
        "(c) Haga un análisis respecto al nivel de complejidad para los modelos (MLP y CNN) en reconocer o clasificar entre un número u otro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpYs5aRTCSkp"
      },
      "source": [
        "## Para la segunda experiencia:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4e2hbFqRC48_"
      },
      "source": [
        "(e) Entrene y evalúe el mismo modelo utilizado con MNIST, ahora con CIFAR100 y comente, sin aplicar ningún cambio ni ejecutar ningún código, quéé aspectos deben considerarse en la arquitectura o entrenamiento para mejorar el resultado obtenido."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpe4gw5WCcg5"
      },
      "source": [
        "(d) Para el modelo basado en VGG6, modifique la etapa de clasificación del moodelo para obtener un mejor resultado de evaluación, en caso exista, y explique por qué con las capas definidas se obtiene un resultado u otro."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0fbJG64DdQm"
      },
      "source": [
        "(f) Si le fuera solicitado desarrollar un modelo para clasificar imágenes de productos que son embalados en una planta de alimentos.\n",
        "Indique los pasos que debe llevar a cabo para obtener dicho modelo.\n",
        "\n",
        "__Nota__: Piense en un proceso desde cero, defina las condiciones que deben cumplirse y la forma en que abordaría el problema."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O1-c0RRBsB0g"
      },
      "source": [
        "### Evaluación:\n",
        "- Para evaluar el trabajo se debe crear un documento pdf dónde se indique:\n",
        "  - La respuesta para cada experiencia y comentarios sobre cada prueba realizada.\n",
        "  - Una sección final de conclusión donde comenten sobre retropropagación y sus comentarios finales respecto a los resultados obtenidos.\n",
        "- El documento debe ser nombrado como \"Taller IA02 - Deep Learning - _nombreAlumno_.pdf\"\n",
        "  - Ejemplo \"Taller IA03 - Deep Learning - Alan Turing.pdf\"\n",
        "- Se debe compartir el notebook y el pdf creado con <aaam@ecomp.poli.br> con copia a <francisco.cruz@ucentral.cl>, <martin.saavedra@alumnos.ucentral.cl>\n",
        "y <ines.apablaza@alumnos.ucentral.cl>\n",
        "\n",
        "### Observaciones:\n",
        "- Debes crear una copia del notebook y guardarlo en Google Drive para no perder los cambios realizados.\n",
        "- Recuerda agregar todo el material auxiliar necesario para fundamentar tus respuestas, referencias a artículos o trabajos relacionados, gráficos, formulas entre otros."
      ]
    }
  ]
}